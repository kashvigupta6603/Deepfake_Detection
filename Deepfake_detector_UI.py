import streamlit as st
import numpy as np
import cv2
import face_recognition
import sounddevice as sd
from scipy.io.wavfile import write
import os
import mss
from d_voice import run_voice_analysis_streamlit
from d_image import MesoNet

# ========== Config ==========
MESO_MODEL = "meso4.h5"
REF_AUDIO = "reference.wav"
TEST_AUDIO = "test_audio.wav"
SAMPLE_RATE = 16000
AUDIO_DURATION = 5
FRAME_SKIP = 5

# ========== Load Model ==========
meso = MesoNet(model_path=MESO_MODEL)

# ========== Audio Recorder ==========
def record_audio(filename, duration=AUDIO_DURATION):
    st.info(f"üéô Recording for {duration} seconds...")
    audio = sd.rec(int(duration * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1)
    sd.wait()
    write(filename, SAMPLE_RATE, audio)
    st.success(f"‚úÖ Saved: {filename}")

# ========== Page Config ==========
st.set_page_config(page_title="Deepfake Detection Suite", layout="wide", page_icon="üß†")

# ========== Light / Dark Mode Toggle ==========
theme = st.sidebar.radio("üåó Theme Mode", ["üåû Light Mode", "üåô Dark Mode"])

if theme == "üåô Dark Mode":
    st.markdown("""
        <style>
            html, body, .main {
                background-color: #0E1117 !important;
                color: white !important;
            }
            .stButton>button {
                background-color: #31333F;
                color: white;
            }
            .stFileUploader {
                background-color: #1E1E1E;
            }
        </style>
    """, unsafe_allow_html=True)
else:
    st.markdown("""
        <style>
            html, body, .main, .block-container, .css-18e3th9 {
                background-color: white !important;
                color: black !important;
            }
            .stButton>button {
                background-color: #f0f0f0;
                color: black;
            }
            .stFileUploader {
                background-color: #ffffff;
            }
            .stAlert, .stAlert > div {
                background-color: inherit !important;
                color: black !important;
            }
            .stAlert .css-1w0z1zr {
                color: black !important;
            }
        </style>
    """, unsafe_allow_html=True)



# ========== Page Title ==========
st.markdown("<h1 style='text-align: center;'>üß† FAUXSHIELD</h1>", unsafe_allow_html=True)
st.markdown("<hr style='border:1px solid gray'>", unsafe_allow_html=True)

# ========== VOICE AUTHENTICATION ==========
st.subheader("üéô Voice Authentication & Deepfake Detection")
st.caption("Upload a reference voice or record live test voice to check authenticity.")

with st.container():
    col1, col2 = st.columns(2)

    with col1:
        uploaded_ref = st.file_uploader("üì§ Upload Reference Voice (WAV)", type=["wav"])
        if uploaded_ref:
            with open(REF_AUDIO, "wb") as f:
                f.write(uploaded_ref.read())
            st.audio(REF_AUDIO, format="audio/wav")
            st.success("‚úÖ Reference voice uploaded successfully.")

    with col2:
        if st.button("üéô Record Test Voice"):
            record_audio(TEST_AUDIO)
        if os.path.exists(TEST_AUDIO):
            st.audio(TEST_AUDIO, format="audio/wav")

# ========== Run Voice Analysis ==========
if os.path.exists(REF_AUDIO) and os.path.exists(TEST_AUDIO):
    if st.button("üöÄ Run Voice Analysis"):
        with st.spinner("Analyzing voice sample..."):
            match, similarity, is_fake, zcr_score = run_voice_analysis_streamlit(REF_AUDIO, TEST_AUDIO)

        st.progress(min(int(similarity * 100), 100), text="üîç Similarity Score")

        st.markdown(f"üß† Cosine Similarity:** {similarity:.4f}")
        st.markdown(f"üéµ ZCR Score (Heuristic):** {zcr_score:.4f}")

        if match and not is_fake:
            st.success("‚úÖ Real speaker matched. Voice is authentic.")
        elif not match and not is_fake:
            st.warning("‚ö† Unknown speaker, but sounds human.")
        elif match and is_fake:
            st.warning("‚ö† Voice matches speaker, but may be synthetically altered.")
        else:
            st.error("üö® Likely deepfake or impersonation detected.")

st.markdown("<hr style='border:1px dashed gray'>", unsafe_allow_html=True)

# ========== IMAGE MONITORING ==========
st.subheader("üñ• Screen-Based Face Monitoring & Deepfake Detection")
st.caption("Analyzes your live screen (e.g. Google Meet) to detect deepfake faces.")

uploaded_ref_image = st.file_uploader("üì∏ Upload Reference Face Image (JPG, PNG)", type=["jpg", "jpeg", "png"])
ref_enc = None

if uploaded_ref_image is not None:
    try:
        img_bytes = uploaded_ref_image.read()
        with open("uploaded_ref.jpg", "wb") as f:
            f.write(img_bytes)

        ref_img = face_recognition.load_image_file("uploaded_ref.jpg")
        ref_encodings = face_recognition.face_encodings(ref_img)

        if not ref_encodings:
            st.error("‚ùå No face found in uploaded reference image.")
        else:
            ref_enc = ref_encodings[0]
            st.success("‚úÖ Reference face image uploaded.")
    except Exception as e:
        st.error(f"‚ùå Error loading image: {e}")
else:
    st.warning("‚ö† Please upload a reference image to enable face authentication.")

# ========== Detection Control ==========
if "detection_running" not in st.session_state:
    st.session_state.detection_running = False

col1, col2 = st.columns(2)
with col1:
    if st.button("‚ñ∂ Start Face Detection"):
        st.session_state.detection_running = True
with col2:
    if st.button("‚èπ Stop Face Detection"):
        st.session_state.detection_running = False

placeholder = st.empty()

# ========== Face Detection ==========
if st.session_state.detection_running and ref_enc is not None:
    with mss.mss() as sct:
        monitor = sct.monitors[1]
        frame_count = 0

        while st.session_state.detection_running:
            frame = np.array(sct.grab(monitor))
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2RGB)

            if frame_count % FRAME_SKIP == 0:
                face_locs = face_recognition.face_locations(rgb_frame)
                face_encs = face_recognition.face_encodings(rgb_frame, face_locs)


                for (top, right, bottom, left), enc in zip(face_locs, face_encs):
                    matched = face_recognition.compare_faces([ref_enc], enc, tolerance=0.6)[0]
                    face_crop = rgb_frame[top:bottom, left:right]

                    if matched:
                        prob = meso.predict(face_crop)
                        label = "REAL" if prob > 0.5 else "FAKE"
                        result = f"‚úÖ Match ‚Äì {label} ({prob*100:.1f}%)"
                        color = (0, 255, 0) if label == "REAL" else (0, 0, 255)
                    else:
                        result = "‚ùå Unknown Face"
                        color = (255, 0, 0)

                    cv2.rectangle(frame, (left, top), (right, bottom), color, 2)
                    cv2.putText(frame, result, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

                    st.info(result)


            placeholder.image(frame, channels="BGR", use_container_width=True)
            frame_count += 1

# ========== Footer ==========
st.markdown("<hr>", unsafe_allow_html=True)
st.caption("üõ° Made with üí° Gurjot Kaur, Kashvi Gupta | Powered by SpeechBrain, FaceNet, and MesoNet.")
